{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e27a68ac-50c5-4557-a9fc-d6966e9d1689",
   "metadata": {},
   "outputs": [],
   "source": [
    "TECHNIQUE_OPTIONS = [\n",
    "    \"Scanning electron microscopy (SEM)\",\n",
    "    \"Transmission electron microscopy (TEM)\",\n",
    "    \"Atomic force microscopy (AFM)\",\n",
    "    \"Reflected light microscopy\"\n",
    "]\n",
    "\n",
    "CATEGORY_OPTIONS = [\n",
    "    \"Metal or alloy\",\n",
    "    \"Ceramic\",\n",
    "    \"Polymer\",\n",
    "    \"Composite\",\n",
    "    \"Fracture\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35322945-f1af-4500-b583-2ba1b241fe32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def technique_mcq_prompt():\n",
    "    return (\n",
    "        \"Look carefully at the microscopy image and identify the imaging technique.\\n\\n\"\n",
    "        \"A. Scanning electron microscopy (SEM)\\n\"\n",
    "        \"B. Transmission electron microscopy (TEM)\\n\"\n",
    "        \"C. Atomic force microscopy (AFM)\\n\"\n",
    "        \"D. Reflected light microscopy\\n\\n\"\n",
    "        \"Answer with only one letter.\"\n",
    "    )\n",
    "\n",
    "def category_mcq_prompt():\n",
    "    return (\n",
    "        \"Which material category best describes the image?\\n\\n\"\n",
    "        \"A. Metal or alloy\\n\"\n",
    "        \"B. Ceramic\\n\"\n",
    "        \"C. Polymer\\n\"\n",
    "        \"D. Composite\\n\"\n",
    "        \"E. Fracture\\n\\n\"\n",
    "        \"Answer with only one letter.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d32f0f39-0754-41fe-9d2e-472abb5e0308",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_answer(text, valid):\n",
    "    text = text.upper()\n",
    "    for v in valid:\n",
    "        if v in text:\n",
    "            return v\n",
    "    return None\n",
    "\n",
    "def gt_to_letter(gt, options):\n",
    "    try:\n",
    "        return chr(ord(\"A\") + options.index(gt))\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "323d9f0c-e850-4d4d-972e-38cbcf717596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import Qwen3VLForConditionalGeneration, AutoProcessor\n",
    "\n",
    "def load_qwen_model(model_path, device=\"cuda\"):\n",
    "    model = Qwen3VLForConditionalGeneration.from_pretrained(\n",
    "        model_path,\n",
    "        torch_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32,\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "\n",
    "    processor = AutoProcessor.from_pretrained(model_path)\n",
    "\n",
    "    model.eval()\n",
    "    return model, processor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7967bd0b-d772-40a0-a9ff-b42b374155fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2410ec1fc4554707906a0f0756d3bcce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "MODEL_PATH = \"/mnt/d/Subham/model/Qwen3-VL-8B-Instruct\"\n",
    "\n",
    "model, processor = load_qwen_model(MODEL_PATH, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c32a798e-7122-49ed-8a36-22304fc3be83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_qwen_vlm(model, processor, image, prompt):\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image\", \"image\": image},\n",
    "                {\"type\": \"text\", \"text\": prompt}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    inputs = processor.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=True,\n",
    "        add_generation_prompt=True,\n",
    "        return_dict=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    inputs = inputs.to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=5,\n",
    "            do_sample=False\n",
    "        )\n",
    "\n",
    "    # IMPORTANT: trim prompt tokens\n",
    "    generated_ids_trimmed = [\n",
    "        out[len(inp):] for inp, out in zip(inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "\n",
    "    output = processor.batch_decode(\n",
    "        generated_ids_trimmed,\n",
    "        skip_special_tokens=True,\n",
    "        clean_up_tokenization_spaces=False\n",
    "    )[0]\n",
    "\n",
    "    return output.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "297be79e-747d-4b5e-a00c-7c8298447fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                | 0/51 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "100%|███████████████████████████████████████████████████████████████████████| 51/51 [53:40<00:00, 63.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total processing time: 3220.61 seconds\n",
      "Average time per image: 63.15 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "CSV_PATH = \"qa.csv\"\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "start_time = time.time()\n",
    "y_true_tech = []\n",
    "y_pred_tech = []\n",
    "\n",
    "y_true_cat = []\n",
    "y_pred_cat = []\n",
    "\n",
    "for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "\n",
    "    # --- Safe image loading ---\n",
    "    try:\n",
    "        image = Image.open(row[\"image_local_path\"]).convert(\"RGB\")\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "    # -------- Technique MCQ --------\n",
    "    tech_out = run_qwen_vlm(\n",
    "        model,\n",
    "        processor,\n",
    "        image,\n",
    "        technique_mcq_prompt()\n",
    "    )\n",
    "\n",
    "    tech_pred = parse_answer(tech_out, [\"A\", \"B\", \"C\", \"D\"])\n",
    "    tech_gt   = gt_to_letter(row[\"technique\"], TECHNIQUE_OPTIONS)\n",
    "\n",
    "    if tech_pred is not None and tech_gt is not None:\n",
    "        y_pred_tech.append(tech_pred)\n",
    "        y_true_tech.append(tech_gt)\n",
    "\n",
    "    # -------- Category MCQ --------\n",
    "    cat_out = run_qwen_vlm(\n",
    "        model,\n",
    "        processor,\n",
    "        image,\n",
    "        category_mcq_prompt()\n",
    "    )\n",
    "\n",
    "    cat_pred = parse_answer(cat_out, [\"A\", \"B\", \"C\", \"D\", \"E\"])\n",
    "    cat_gt   = gt_to_letter(row[\"categories\"], CATEGORY_OPTIONS)\n",
    "\n",
    "    if cat_pred is not None and cat_gt is not None:\n",
    "        y_pred_cat.append(cat_pred)\n",
    "        y_true_cat.append(cat_gt)\n",
    "# Calculate total time\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\nTotal processing time: {total_time:.2f} seconds\")\n",
    "print(f\"Average time per image: {total_time/len(df):.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "565bfc48-f6b7-474a-8026-b4dd60bd1f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    balanced_accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "def print_metrics(y_true, y_pred, name):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    bal_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred,\n",
    "        average=\"macro\",\n",
    "        zero_division=0\n",
    "    )\n",
    "\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(f\"Accuracy           : {acc:.3f}\")\n",
    "    print(f\"Balanced Accuracy  : {bal_acc:.3f}\")\n",
    "    print(f\"Macro Precision    : {prec:.3f}\")\n",
    "    print(f\"Macro Recall       : {rec:.3f}\")\n",
    "    print(f\"Macro F1-score     : {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72040ec9-96ab-4fad-b1a2-0c98cd26e5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Technique Classification ===\n",
      "Accuracy           : 0.913\n",
      "Balanced Accuracy  : 0.862\n",
      "Macro Precision    : 0.933\n",
      "Macro Recall       : 0.862\n",
      "Macro F1-score     : 0.888\n",
      "\n",
      "=== Category Classification ===\n",
      "Accuracy           : 0.378\n",
      "Balanced Accuracy  : 0.382\n",
      "Macro Precision    : 0.529\n",
      "Macro Recall       : 0.305\n",
      "Macro F1-score     : 0.329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subham/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2801: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    }
   ],
   "source": [
    "print_metrics(y_true_tech, y_pred_tech, \"Technique Classification\")\n",
    "print_metrics(y_true_cat,  y_pred_cat,  \"Category Classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d866c3-9a96-439f-9df6-74e87f3df1b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
